{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = get_dataset(\"traffic\")\n",
    "freq = dataset.metadata.freq\n",
    "prediction_length = dataset.metadata.prediction_length\n",
    "train_dataset = dataset.train\n",
    "test_dataset = dataset.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_example = next(iter(dataset.train))\n",
    "test_example = next(iter(dataset.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10  # number of time series\n",
    "T = 100  # number of timesteps\n",
    "prediction_length = 25\n",
    "freq = \"1H\"\n",
    "custom_dataset = np.random.normal(size=(N, T))\n",
    "start = pd.Period(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0]['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "train_ds = ListDataset(\n",
    "    [{\"target\": x, \"start\": start} for x in custom_dataset[:, :-prediction_length]],\n",
    "    freq=freq,\n",
    ")\n",
    "# test dataset: use the whole dataset, add \"target\" and \"start\" fields\n",
    "test_ds = ListDataset(\n",
    "    [{\"target\": x, \"start\": start} for x in custom_dataset], freq=freq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: \n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | DLinearModel | 1.4 K \n",
      "---------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | DLinearModel | 1.4 K \n",
      "---------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 50/? [00:11<00:00,  4.36it/s, v_num=4, train_loss=1.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 0, global step 50: 'train_loss' reached 1.49011 (best 1.49011), saving model to '/home/wendeldr/git/spacetimeformer/lightning_logs/version_4/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.49011 (best 1.49011), saving model to '/home/wendeldr/git/spacetimeformer/lightning_logs/version_4/checkpoints/epoch=0-step=50.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: |          | 50/? [00:11<00:00,  4.26it/s, v_num=4, train_loss=1.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 1, global step 100: 'train_loss' reached 1.46239 (best 1.46239), saving model to '/home/wendeldr/git/spacetimeformer/lightning_logs/version_4/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 1.46239 (best 1.46239), saving model to '/home/wendeldr/git/spacetimeformer/lightning_logs/version_4/checkpoints/epoch=1-step=100.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: |          | 49/? [00:11<00:00,  4.31it/s, v_num=4, train_loss=1.460]"
     ]
    }
   ],
   "source": [
    "from gluonts.torch.model.d_linear.estimator import DLinearEstimator\n",
    "\n",
    "\n",
    "estimator = DLinearEstimator(\n",
    "    prediction_length=1,\n",
    "    context_length=32,\n",
    "    hidden_dimension=None,\n",
    "    scaling=False,\n",
    "    batch_size=2000,\n",
    "    trainer_kwargs=dict(max_epochs=100)\n",
    ")\n",
    "\n",
    "predictor = estimator.train(\n",
    "    training_data=train_ds, \n",
    "    cache_data=True, \n",
    "    shuffle_buffer_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target', 'start', 'feat_static_cat', 'item_id'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacetimeformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
