{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing\n",
    "import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacetimeformer as stf\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "\n",
    "default_config = {\n",
    "    # fixed but maybe change...\n",
    "    'batch_size':100,\n",
    "    'workers':1,\n",
    "    'init_lr':1e-10,\n",
    "    'base_lr':0.0005,\n",
    "    'context_points':3,\n",
    "    'target_points':1,\n",
    "    'd_model':15,\n",
    "    'd_qk':15,\n",
    "    'd_v':15,\n",
    "    'd_ff':60,\n",
    "    'n_heads':1,\n",
    "    'enc_layers':1,\n",
    "    'dec_layers':1,\n",
    "    'global_self_attn':'full',\n",
    "    'local_self_attn':'full',\n",
    "    'global_cross_attn':'full',\n",
    "    'local_cross_attn':'full',\n",
    "    'no_val':False,\n",
    "    'no_time':False,\n",
    "    'no_space':False,\n",
    "    'no_given':False,\n",
    "\n",
    "    # directly set parameters\n",
    "    'gpus':[0],\n",
    "    # 'gpus':None,\n",
    "    'strategy':'dp',\n",
    "    \"time_resolution\": 1,\n",
    "    \"start_token_len\": 0,\n",
    "    \"attn_factor\": 5,\n",
    "    \"dropout_emb\": 0.2,\n",
    "    \"dropout_attn_out\": 0,\n",
    "    \"dropout_attn_matrix\": 0,\n",
    "    \"dropout_qkv\": 0,\n",
    "    \"dropout_ff\": 0.3,\n",
    "    \"pos_emb_type\": 'abs',\n",
    "    \"no_final_norm\": False,\n",
    "    \"performer_kernel\": 'relu',\n",
    "    \"performer_redraw_interval\": 100,\n",
    "    \"attn_time_windows\": 1,\n",
    "    \"use_shifted_time_windows\": False,\n",
    "    \"norm\": 'batch',\n",
    "    \"activation\": 'gelu',\n",
    "    \"warmup_steps\": 0,\n",
    "    \"decay_factor\": 0.25,\n",
    "    \"initial_downsample_convs\": 0,\n",
    "    \"intermediate_downsample_convs\": 0,\n",
    "    \"embed_method\": 'spatio-temporal',\n",
    "    \"l2_coeff\": 0.000001,\n",
    "    \"loss\": 'mse',\n",
    "    \"class_loss_imp\": 0.1,\n",
    "    \"recon_loss_imp\": 0,\n",
    "    \"time_emb_dim\": 3,\n",
    "    \"null_value\": None,\n",
    "    \"pad_value\": None,\n",
    "    \"linear_window\": 0,\n",
    "    \"use_revin\": False,\n",
    "    \"linear_shared_weights\": False,\n",
    "    \"use_seasonal_decomp\": False,\n",
    "    \"recon_mask_skip_all\": 1,\n",
    "    \"recon_mask_max_seq_len\": 5,\n",
    "    \"recon_mask_drop_seq\": 0.2,\n",
    "    \"recon_mask_drop_standard\": 0.1,\n",
    "    \"recon_mask_drop_full\": 0.05,\n",
    "}\n",
    "sweep_config = {\n",
    "    'method': 'random', #grid, random\n",
    "    'parameters': {\n",
    "        'base_lr':   {'distribution': 'log_uniform_values', 'min': 1e-10, 'max': 0.01},\n",
    "    },\n",
    "    # only for bayes sweeps\n",
    "    'metric': {\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val/smape'\n",
    "    },\n",
    "}\n",
    "\n",
    "def create_dataset(config):\n",
    "    INV_SCALER = lambda x: x\n",
    "    SCALER = lambda x: x\n",
    "    NULL_VAL = None\n",
    "    PLOT_VAR_IDXS = None\n",
    "    PLOT_VAR_NAMES = None\n",
    "    PAD_VAL = None\n",
    "\n",
    "    fs = 256  # Sampling rate (Hz)\n",
    "    T = 1  # Length of epochs (s)\n",
    "    f = 25  # Frequency of sinusoids (Hz)\n",
    "    t = np.arange(0, T, 1 / fs)  # Time array\n",
    "    A = 1  # Amplitude\n",
    "    sigma = 0.1  # Gaussian noise variance\n",
    "\n",
    "    # Damping/growth factor\n",
    "    k = 4\n",
    "\n",
    "    # Number of repetitions\n",
    "    N = 6  # Replace with desired number of repetitions\n",
    "\n",
    "    # Initializing the data array\n",
    "    data = []\n",
    "\n",
    "    # Phase differences for the sine waves\n",
    "    phase_differences = [0, np.pi]\n",
    "    names = ['0 (0°)', 'π (180°)']\n",
    "\n",
    "    # Time variable for the repeating dampened wave\n",
    "    repeating_t = t % (T / N)\n",
    "\n",
    "    # Append dampened sine wave (repeating)\n",
    "    dampened_wave = A * np.exp(-k * repeating_t) * np.sin(2 * np.pi * f * repeating_t)\n",
    "    data.append(dampened_wave)\n",
    "\n",
    "    # Append standard and phase-shifted sine waves\n",
    "    for ps in phase_differences:\n",
    "        # Create the sine wave with phase shift\n",
    "        sig = A*np.sin(2 * np.pi * f * t - ps)\n",
    "        data.append(sig)\n",
    "\n",
    "    data = np.array(data).T\n",
    "    # Update names for the new waves\n",
    "    names.insert(0, \"Dampened\")\n",
    "\n",
    "    PLOT_VAR_NAMES = names\n",
    "    PLOT_VAR_IDXS = np.arange(0, len(names))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=PLOT_VAR_NAMES)\n",
    "    df[\"Datetime\"] = pd.date_range(start=\"1/1/2020\", periods=df.shape[0], freq=\"ms\")\n",
    "\n",
    "    dset = stf.data.CSVTimeSeries(\n",
    "        data_path=None,\n",
    "        raw_df=df,\n",
    "        target_cols=PLOT_VAR_NAMES,\n",
    "        ignore_cols=[],\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        normalize=False,\n",
    "        time_col_name=\"Datetime\",\n",
    "        time_features=[\"millisecond\"],\n",
    "    )\n",
    "    yc_dim = data.shape[1]\n",
    "    yt_dim = data.shape[1]\n",
    "    x_dim = dset.time_cols.shape[0]\n",
    "\n",
    "    DATA_MODULE = stf.data.DataModule(\n",
    "        datasetCls=stf.data.CSVTorchDset,\n",
    "        dataset_kwargs={\n",
    "            \"csv_time_series\": dset,\n",
    "            \"context_points\": config['context_points'],\n",
    "            \"target_points\": config['target_points'],\n",
    "            \"time_resolution\": config['time_resolution'],\n",
    "        },\n",
    "        batch_size=config['batch_size'],\n",
    "        workers=config['workers'],\n",
    "        overfit=False,\n",
    "    )\n",
    "    INV_SCALER = dset.reverse_scaling\n",
    "    SCALER = dset.apply_scaling\n",
    "    NULL_VAL = None\n",
    "    return (\n",
    "        DATA_MODULE,\n",
    "        INV_SCALER,\n",
    "        SCALER,\n",
    "        NULL_VAL,\n",
    "        PLOT_VAR_IDXS,\n",
    "        PLOT_VAR_NAMES,\n",
    "        PAD_VAL,\n",
    "        x_dim,\n",
    "        yc_dim,\n",
    "        yt_dim\n",
    "    )\n",
    "\n",
    "def create_model(config, x_dim, yc_dim, yt_dim):\n",
    "    max_seq_len = config['context_points'] + config['target_points']\n",
    "\n",
    "    forecaster = stf.spacetimeformer_model.Spacetimeformer_Forecaster(\n",
    "        d_x=x_dim,\n",
    "        d_yc=yc_dim,\n",
    "        d_yt=yt_dim,\n",
    "        max_seq_len=max_seq_len,    \n",
    "        start_token_len=config['start_token_len'],\n",
    "        attn_factor=config['attn_factor'],\n",
    "        d_model=config['d_model'],\n",
    "        d_queries_keys=config['d_qk'],\n",
    "        d_values=config['d_v'],\n",
    "        n_heads=config['n_heads'],\n",
    "        e_layers=config['enc_layers'],\n",
    "        d_layers=config['dec_layers'],\n",
    "        d_ff=config['d_ff'],\n",
    "        dropout_emb=config['dropout_emb'],\n",
    "        dropout_attn_out=config['dropout_attn_out'],\n",
    "        dropout_attn_matrix=config['dropout_attn_matrix'],\n",
    "        dropout_qkv=config['dropout_qkv'],\n",
    "        dropout_ff=config['dropout_ff'],\n",
    "        pos_emb_type=config['pos_emb_type'],\n",
    "        use_final_norm=not config['no_final_norm'],\n",
    "        global_self_attn=config['global_self_attn'],\n",
    "        local_self_attn=config['local_self_attn'],\n",
    "        global_cross_attn=config['global_cross_attn'],\n",
    "        local_cross_attn=config['local_cross_attn'],\n",
    "        performer_kernel=config['performer_kernel'],\n",
    "        performer_redraw_interval=config['performer_redraw_interval'],\n",
    "        attn_time_windows=config['attn_time_windows'],\n",
    "        use_shifted_time_windows=config['use_shifted_time_windows'],\n",
    "        norm=config['norm'],\n",
    "        activation=config['activation'],\n",
    "        init_lr=config['init_lr'],\n",
    "        base_lr=config['base_lr'],\n",
    "        warmup_steps=config['warmup_steps'],\n",
    "        decay_factor=config['decay_factor'],\n",
    "        initial_downsample_convs=config['initial_downsample_convs'],\n",
    "        intermediate_downsample_convs=config['intermediate_downsample_convs'],\n",
    "        embed_method=config['embed_method'],\n",
    "        l2_coeff=config['l2_coeff'],\n",
    "        loss=config['loss'],\n",
    "        class_loss_imp=config['class_loss_imp'],\n",
    "        recon_loss_imp=config['recon_loss_imp'],\n",
    "        time_emb_dim=config['time_emb_dim'],\n",
    "        null_value=config['null_value'],\n",
    "        pad_value=config['pad_value'],\n",
    "        linear_window=config['linear_window'],\n",
    "        use_revin=config['use_revin'],\n",
    "        linear_shared_weights=config['linear_shared_weights'],\n",
    "        use_seasonal_decomp=config['use_seasonal_decomp'],\n",
    "        use_val=not config['no_val'],\n",
    "        use_time=not config['no_time'],\n",
    "        use_space=not config['no_space'],\n",
    "        use_given=not config['no_given'],\n",
    "        recon_mask_skip_all=config['recon_mask_skip_all'],\n",
    "        recon_mask_max_seq_len=config['recon_mask_max_seq_len'],\n",
    "        recon_mask_drop_seq=config['recon_mask_drop_seq'],\n",
    "        recon_mask_drop_standard=config['recon_mask_drop_standard'],\n",
    "        recon_mask_drop_full=config['recon_mask_drop_full'],\n",
    "    )\n",
    "    return forecaster\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    # If you are using CUDA\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def train(config=default_config):   \n",
    "    # place values from default_config into config if not already set\n",
    "    for key in default_config:\n",
    "        if key not in config:\n",
    "            config[key] = default_config[key]\n",
    "\n",
    "    set_seed(42)\n",
    "    (data_module,\n",
    "    inv_scaler,\n",
    "    scaler,\n",
    "    null_val,\n",
    "    plot_var_idxs,\n",
    "    plot_var_names,\n",
    "    pad_val,\n",
    "    x_dim,\n",
    "    yc_dim,\n",
    "    yt_dim) = create_dataset(config)\n",
    "\n",
    "    forecaster = create_model(config, x_dim=x_dim, yc_dim=yc_dim, yt_dim=yt_dim)\n",
    "    forecaster.eval()\n",
    "\n",
    "    cp = config['context_points']\n",
    "    tp = config['target_points']\n",
    "    N_batch = config['batch_size']\n",
    "    N_time_representations = 1\n",
    "\n",
    "    # test_samples = next(iter(data_module.test_dataloader()))\n",
    "    # for x in test_samples:\n",
    "    #     print(x.shape)\n",
    "\n",
    "     # x_c, y_c, x_t, y_t,\n",
    "    forecaster(torch.randn(N_batch, cp, N_time_representations),\n",
    "               torch.randn(N_batch, cp, yc_dim),\n",
    "               torch.randn(N_batch, tp, N_time_representations),\n",
    "               torch.randn(N_batch, tp, yc_dim))\n",
    "\n",
    "    # torch.onnx.export(forecaster,\n",
    "    #                   # x_c, y_c, x_t, y_t,\n",
    "    #              (torch.randn(1, cp, 1),torch.randn(1, cp, yc_dim),torch.randn(1, tp, 1),torch.randn(1, tp, yc_dim)),\n",
    "    #              \"stf.onnx\",\n",
    "    #              verbose=False,\n",
    "    #              export_params=True,\n",
    "    #              )\n",
    "    \n",
    "    forecaster.set_inv_scaler(inv_scaler)\n",
    "    forecaster.set_scaler(scaler)\n",
    "    forecaster.set_null_value(null_val)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=config.gpus,\n",
    "        strategy=config.strategy,\n",
    "        accelerator=config.strategy,\n",
    "        gradient_clip_val=0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        overfit_batches=0,\n",
    "        accumulate_grad_batches=1,\n",
    "        sync_batchnorm=False,\n",
    "        limit_val_batches=1,\n",
    "        max_epochs=10,\n",
    "        log_every_n_steps=1,\n",
    "        val_check_interval=1,\n",
    "        callbacks=[pl.callbacks.LearningRateMonitor()],\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.fit(forecaster, datamodule=data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "(data_module,\n",
    "inv_scaler,\n",
    "scaler,\n",
    "null_val,\n",
    "plot_var_idxs,\n",
    "plot_var_names,\n",
    "pad_val,\n",
    "x_dim,\n",
    "yc_dim,\n",
    "yt_dim) = create_dataset(default_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "(data_module,\n",
    "inv_scaler,\n",
    "scaler,\n",
    "null_val,\n",
    "plot_var_idxs,\n",
    "plot_var_names,\n",
    "pad_val,\n",
    "x_dim,\n",
    "yc_dim,\n",
    "yt_dim) = create_dataset(default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'CSVTorchDset' has no attribute 'context_points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/dan/Data/git/spacetimeformer/spacetimeformer/simple_small.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B100.112.86.136/media/dan/Data/git/spacetimeformer/spacetimeformer/simple_small.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m data_module\u001b[39m.\u001b[39;49mdatasetCls\u001b[39m.\u001b[39;49mcontext_points\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'CSVTorchDset' has no attribute 'context_points'"
     ]
    }
   ],
   "source": [
    "data_module.datasetCls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecaster = create_model(default_config, x_dim=x_dim, yc_dim=yc_dim, yt_dim=yt_dim)\n",
    "forecaster.eval()\n",
    "\n",
    "cp = default_config['context_points']\n",
    "tp = default_config['target_points']\n",
    "N_batch = default_config['batch_size']\n",
    "N_time_representations = 1\n",
    "\n",
    "# test_samples = next(iter(data_module.test_dataloader()))\n",
    "# for x in test_samples:\n",
    "#     print(x.shape)\n",
    "\n",
    "    # x_c, y_c, x_t, y_t,\n",
    "forecaster(torch.randn(N_batch, cp, N_time_representations),\n",
    "            torch.randn(N_batch, cp, yc_dim),\n",
    "            torch.randn(N_batch, tp, N_time_representations),\n",
    "            torch.randn(N_batch, tp, yc_dim))\n",
    "\n",
    "# torch.onnx.export(forecaster,\n",
    "#                   # x_c, y_c, x_t, y_t,\n",
    "#              (torch.randn(1, cp, 1),torch.randn(1, cp, yc_dim),torch.randn(1, tp, 1),torch.randn(1, tp, yc_dim)),\n",
    "#              \"stf.onnx\",\n",
    "#              verbose=False,\n",
    "#              export_params=True,\n",
    "#              )\n",
    "\n",
    "forecaster.set_inv_scaler(inv_scaler)\n",
    "forecaster.set_scaler(scaler)\n",
    "forecaster.set_null_value(null_val)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=config.gpus,\n",
    "    strategy=config.strategy,\n",
    "    accelerator=config.strategy,\n",
    "    gradient_clip_val=0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    overfit_batches=0,\n",
    "    accumulate_grad_batches=1,\n",
    "    sync_batchnorm=False,\n",
    "    limit_val_batches=1,\n",
    "    max_epochs=10,\n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval=1,\n",
    "    callbacks=[pl.callbacks.LearningRateMonitor()],\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(forecaster, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
