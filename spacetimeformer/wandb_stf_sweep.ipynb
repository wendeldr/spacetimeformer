{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwendeldr\u001b[0m (\u001b[33mponderingparameters\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacetimeformer as stf\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(config):\n",
    "    INV_SCALER = lambda x: x\n",
    "    SCALER = lambda x: x\n",
    "    NULL_VAL = None\n",
    "    PLOT_VAR_IDXS = None\n",
    "    PLOT_VAR_NAMES = None\n",
    "    PAD_VAL = None\n",
    "    fs = 2048  # sampling rate (Hz)\n",
    "    T = 2  # length of epochs (s)\n",
    "    f = 100  # frequency of sinusoids (Hz)\n",
    "    t = np.arange(0, T, 1 / fs)\n",
    "    A = 1  # Amplitude\n",
    "    sigma = 0.1  # Gaussian noise variance\n",
    "\n",
    "    # Damping/growth factor\n",
    "    k = 0.1\n",
    "\n",
    "    # Initializing the data array\n",
    "    data = []\n",
    "\n",
    "    # Phase differences for the sine waves\n",
    "    phase_differences = [0, np.pi]\n",
    "    names = ['0 (0°)', 'π (180°)']\n",
    "\n",
    "    # Append dampened sine wave\n",
    "    dampened_wave = A * np.exp(-k * t) * np.sin(2 * np.pi * f * t)\n",
    "    data.append(dampened_wave)\n",
    "\n",
    "    # Append standard and phase-shifted sine waves\n",
    "    for ps in phase_differences:\n",
    "        # Create the sine wave with phase shift\n",
    "        sig = np.sin(2 * np.pi * f * t - ps)\n",
    "        data.append(sig)\n",
    "\n",
    "    data = np.array(data).T\n",
    "    # Update names for the new waves\n",
    "    names.insert(0, \"Dampened\")\n",
    "\n",
    "    PLOT_VAR_NAMES = names\n",
    "    PLOT_VAR_IDXS = np.arange(0, len(names))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=PLOT_VAR_NAMES)\n",
    "    df[\"Datetime\"] = pd.date_range(start=\"1/1/2020\", periods=df.shape[0], freq=\"D\")\n",
    "\n",
    "    dset = stf.data.CSVTimeSeries(\n",
    "        data_path=None,\n",
    "        raw_df=df,\n",
    "        target_cols=PLOT_VAR_NAMES,\n",
    "        ignore_cols=[],\n",
    "        val_split=0.2,\n",
    "        test_split=0.2,\n",
    "        normalize=True,\n",
    "        time_col_name=\"Datetime\",\n",
    "        time_features=[\"day\"],\n",
    "    )\n",
    "    yc_dim = data.shape[1]\n",
    "    yt_dim = data.shape[1]\n",
    "    x_dim = dset.time_cols.shape[0]\n",
    "\n",
    "    DATA_MODULE = stf.data.DataModule(\n",
    "        datasetCls=stf.data.CSVTorchDset,\n",
    "        dataset_kwargs={\n",
    "            \"csv_time_series\": dset,\n",
    "            \"context_points\": config.context_points,\n",
    "            \"target_points\": config.target_points,\n",
    "            \"time_resolution\": config.time_resolution,\n",
    "        },\n",
    "        batch_size=config.batch_size,\n",
    "        workers=config.workers,\n",
    "        overfit=False,\n",
    "    )\n",
    "    INV_SCALER = dset.reverse_scaling\n",
    "    SCALER = dset.apply_scaling\n",
    "    NULL_VAL = None\n",
    "    return (\n",
    "        DATA_MODULE,\n",
    "        INV_SCALER,\n",
    "        SCALER,\n",
    "        NULL_VAL,\n",
    "        PLOT_VAR_IDXS,\n",
    "        PLOT_VAR_NAMES,\n",
    "        PAD_VAL,\n",
    "        x_dim,\n",
    "        yc_dim,\n",
    "        yt_dim\n",
    "    )\n",
    "\n",
    "def create_model(config, x_dim, yc_dim, yt_dim):\n",
    "    max_seq_len = config.context_points + config.target_points\n",
    "\n",
    "    forecaster = stf.spacetimeformer_model.Spacetimeformer_Forecaster(\n",
    "        d_x=x_dim,\n",
    "        d_yc=yc_dim,\n",
    "        d_yt=yt_dim,\n",
    "        max_seq_len=max_seq_len,\n",
    "        start_token_len=config.start_token_len,\n",
    "        attn_factor=config.attn_factor,\n",
    "        d_model=config.d_model,\n",
    "        d_queries_keys=config.d_qk,\n",
    "        d_values=config.d_v,\n",
    "        n_heads=config.n_heads,\n",
    "        e_layers=config.enc_layers,\n",
    "        d_layers=config.dec_layers,\n",
    "        d_ff=config.d_ff,\n",
    "        dropout_emb=config.dropout_emb,\n",
    "        dropout_attn_out=config.dropout_attn_out,\n",
    "        dropout_attn_matrix=config.dropout_attn_matrix,\n",
    "        dropout_qkv=config.dropout_qkv,\n",
    "        dropout_ff=config.dropout_ff,\n",
    "        pos_emb_type=config.pos_emb_type,\n",
    "        use_final_norm=not config.no_final_norm,\n",
    "        global_self_attn=config.global_self_attn,\n",
    "        local_self_attn=config.local_self_attn,\n",
    "        global_cross_attn=config.global_cross_attn,\n",
    "        local_cross_attn=config.local_cross_attn,\n",
    "        performer_kernel=config.performer_kernel,\n",
    "        performer_redraw_interval=config.performer_redraw_interval,\n",
    "        attn_time_windows=config.attn_time_windows,\n",
    "        use_shifted_time_windows=config.use_shifted_time_windows,\n",
    "        norm=config.norm,\n",
    "        activation=config.activation,\n",
    "        init_lr=config.init_lr,\n",
    "        base_lr=config.base_lr,\n",
    "        warmup_steps=config.warmup_steps,\n",
    "        decay_factor=config.decay_factor,\n",
    "        initial_downsample_convs=config.initial_downsample_convs,\n",
    "        intermediate_downsample_convs=config.intermediate_downsample_convs,\n",
    "        embed_method=config.embed_method,\n",
    "        l2_coeff=config.l2_coeff,\n",
    "        loss=config.loss,\n",
    "        class_loss_imp=config.class_loss_imp,\n",
    "        recon_loss_imp=config.recon_loss_imp,\n",
    "        time_emb_dim=config.time_emb_dim,\n",
    "        null_value=config.null_value,\n",
    "        pad_value=config.pad_value,\n",
    "        linear_window=config.linear_window,\n",
    "        use_revin=config.use_revin,\n",
    "        linear_shared_weights=config.linear_shared_weights,\n",
    "        use_seasonal_decomp=config.use_seasonal_decomp,\n",
    "        use_val=not config.no_val,\n",
    "        use_time=not config.no_time,\n",
    "        use_space=not config.no_space,\n",
    "        use_given=not config.no_given,\n",
    "        recon_mask_skip_all=config.recon_mask_skip_all,\n",
    "        recon_mask_max_seq_len=config.recon_mask_max_seq_len,\n",
    "        recon_mask_drop_seq=config.recon_mask_drop_seq,\n",
    "        recon_mask_drop_standard=config.recon_mask_drop_standard,\n",
    "        recon_mask_drop_full=config.recon_mask_drop_full,\n",
    "    )\n",
    "    return forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    # If you are using CUDA\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(config=config,project=\"sweep\"):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        set_seed(42)\n",
    "        (data_module,\n",
    "        inv_scaler,\n",
    "        scaler,\n",
    "        null_val,\n",
    "        plot_var_idxs,\n",
    "        plot_var_names,\n",
    "        pad_val,\n",
    "        x_dim,\n",
    "        yc_dim,\n",
    "        yt_dim) = create_dataset(config)\n",
    "\n",
    "        forecaster = create_model(config, x_dim=x_dim, yc_dim=yc_dim, yt_dim=yt_dim)\n",
    "        forecaster.set_inv_scaler(inv_scaler)\n",
    "        forecaster.set_scaler(scaler)\n",
    "        forecaster.set_null_value(null_val)\n",
    "\n",
    "        wandb_logger = WandbLogger()\n",
    "\n",
    "\n",
    "        # wandb_logger.watch(module.net)\n",
    "    \n",
    "        trainer = pl.Trainer(\n",
    "            gpus=config.gpus,\n",
    "            logger=wandb_logger,\n",
    "            strategy=config.strategy,\n",
    "            accelerator=config.strategy,\n",
    "            gradient_clip_val=0,\n",
    "            gradient_clip_algorithm=\"norm\",\n",
    "            overfit_batches=0,\n",
    "            accumulate_grad_batches=1,\n",
    "            sync_batchnorm=False,\n",
    "            limit_val_batches=1,\n",
    "            max_epochs=10,\n",
    "            log_every_n_steps=1,\n",
    "            val_check_interval=1,\n",
    "            deterministic=True,\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        trainer.fit(forecaster, datamodule=data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ksz0c2gw\n",
      "Sweep URL: https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rtwi4ueb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_factor: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_time_windows: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_lr: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_loss_imp: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcontext_points: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_ff: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_qk: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_v: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_factor: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_attn_matrix: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_attn_out: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_emb: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_ff: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_qkv: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_method: spatio-temporal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tglobal_cross_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tglobal_self_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgpus: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_lr: 1e-10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_downsample_convs: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tintermediate_downsample_convs: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_coeff: 1e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlinear_shared_weights: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlinear_window: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlocal_cross_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlocal_self_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_final_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_given: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_space: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_time: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_val: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm: batch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnull_value: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpad_value: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tperformer_kernel: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tperformer_redraw_interval: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpos_emb_type: abs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_loss_imp: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_drop_full: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_drop_seq: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_drop_standard: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_max_seq_len: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_skip_all: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstart_token_len: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstrategy: dp\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_points: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_emb_dim: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_resolution: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_revin: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_seasonal_decomp: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_shifted_time_windows: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tworkers: 10\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/dan/Data/git/spacetimeformer/spacetimeformer/wandb/run-20231129_130248-rtwi4ueb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/rtwi4ueb' target=\"_blank\">warm-sweep-1</a></strong> to <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/rtwi4ueb' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/rtwi4ueb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecaster\n",
      "\tL2: 1e-06\n",
      "\tLinear Window: 0\n",
      "\tLinear Shared Weights: False\n",
      "\tRevIN: False\n",
      "\tDecomposition: False\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "LocalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "Using Embedding: spatio-temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: False\n",
      "Time Embedding: False\n",
      "Val Embedding: False\n",
      "Given Embedding: False\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.1, Seq (max len = 5) 0.2, Skip All Drop 1\n",
      " *** Spacetimeformer (v1.5) Summary: *** \n",
      "\t\tModel Dim: 100\n",
      "\t\tFF Dim: 400\n",
      "\t\tEnc Layers: 1\n",
      "\t\tDec Layers: 1\n",
      "\t\tEmbed Dropout: 0.2\n",
      "\t\tFF Dropout: 0.3\n",
      "\t\tAttn Out Dropout: 0\n",
      "\t\tAttn Matrix Dropout: 0\n",
      "\t\tQKV Dropout: 0\n",
      "\t\tL2 Coeff: 1e-06\n",
      "\t\tWarmup Steps: 0\n",
      "\t\tNormalization Scheme: batch\n",
      "\t\tAttention Time Windows: 1\n",
      "\t\tShifted Time Windows: False\n",
      "\t\tPosition Emb Type: abs\n",
      "\t\tRecon Loss Imp: 0\n",
      " ***                                  *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:345: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:287: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:597: UserWarning: 'dp' is not supported on CPUs, hence setting `strategy='ddp'`.\n",
      "  rank_zero_warn(f\"{strategy_flag!r} is not supported on CPUs, hence setting `strategy='ddp'`.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1188629/3249414189.py\", line 30, in train\n",
      "    trainer = pl.Trainer(\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\", line 339, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 486, in __init__\n",
      "    self._accelerator_connector = AcceleratorConnector(\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\", line 210, in __init__\n",
      "    self._lazy_init_strategy()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\", line 760, in _lazy_init_strategy\n",
      "    raise MisconfigurationException(\n",
      "pytorch_lightning.utilities.exceptions.MisconfigurationException: `Trainer(strategy='ddp')` or `Trainer(accelerator='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-sweep-1</strong> at: <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/rtwi4ueb' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/rtwi4ueb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231129_130248-rtwi4ueb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run rtwi4ueb errored: MisconfigurationException(\"`Trainer(strategy='ddp')` or `Trainer(accelerator='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run rtwi4ueb errored: MisconfigurationException(\"`Trainer(strategy='ddp')` or `Trainer(accelerator='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: isqypcg7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_factor: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_time_windows: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_lr: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_loss_imp: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcontext_points: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_ff: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_qk: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_v: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay_factor: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_attn_matrix: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_attn_out: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_emb: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_ff: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_qkv: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_method: spatio-temporal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tglobal_cross_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tglobal_self_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgpus: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_lr: 1e-10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_downsample_convs: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tintermediate_downsample_convs: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_coeff: 1e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlinear_shared_weights: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlinear_window: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlocal_cross_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlocal_self_attn: full\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: mse\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_final_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_given: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_space: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_time: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_val: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnorm: batch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnull_value: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpad_value: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tperformer_kernel: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tperformer_redraw_interval: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpos_emb_type: abs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_loss_imp: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_drop_full: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_drop_seq: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_drop_standard: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_max_seq_len: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trecon_mask_skip_all: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstart_token_len: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstrategy: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_points: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_emb_dim: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_resolution: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_revin: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_seasonal_decomp: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_shifted_time_windows: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tworkers: 10\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/dan/Data/git/spacetimeformer/spacetimeformer/wandb/run-20231129_130304-isqypcg7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/isqypcg7' target=\"_blank\">fine-sweep-2</a></strong> to <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/sweeps/ksz0c2gw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/isqypcg7' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/isqypcg7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:345: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1823: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\n",
      "  | Name            | Type            | Params\n",
      "----------------------------------------------------\n",
      "0 | spacetimeformer | Spacetimeformer | 415 K \n",
      "----------------------------------------------------\n",
      "415 K     Trainable params\n",
      "0         Non-trainable params\n",
      "415 K     Total params\n",
      "1.661     Total estimated model params size (MB)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'l2_coeff' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loss' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'linear_window' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'linear_shared_weights' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'use_revin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'use_seasonal_decomp' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'start_token_len' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'attn_factor' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'd_model' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'n_heads' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'd_ff' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout_emb' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout_qkv' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout_ff' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout_attn_out' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout_attn_matrix' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pos_emb_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'global_self_attn' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'local_self_attn' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'global_cross_attn' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'local_cross_attn' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'performer_kernel' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'embed_method' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'performer_redraw_interval' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'attn_time_windows' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'use_shifted_time_windows' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'activation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'norm' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'init_lr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'base_lr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'decay_factor' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_downsample_convs' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'intermediate_downsample_convs' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'class_loss_imp' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'recon_loss_imp' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'time_emb_dim' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'null_value' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pad_value' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'recon_mask_skip_all' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'recon_mask_max_seq_len' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'recon_mask_drop_seq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'recon_mask_drop_standard' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'recon_mask_drop_full' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecaster\n",
      "\tL2: 1e-06\n",
      "\tLinear Window: 0\n",
      "\tLinear Shared Weights: False\n",
      "\tRevIN: False\n",
      "\tDecomposition: False\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "LocalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): FullAttention(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out_projection): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0, inplace=False)\n",
      ")\n",
      "Using Embedding: spatio-temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: False\n",
      "Time Embedding: False\n",
      "Val Embedding: False\n",
      "Given Embedding: False\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.1, Seq (max len = 5) 0.2, Skip All Drop 1\n",
      " *** Spacetimeformer (v1.5) Summary: *** \n",
      "\t\tModel Dim: 100\n",
      "\t\tFF Dim: 400\n",
      "\t\tEnc Layers: 1\n",
      "\t\tDec Layers: 1\n",
      "\t\tEmbed Dropout: 0.2\n",
      "\t\tFF Dropout: 0.3\n",
      "\t\tAttn Out Dropout: 0\n",
      "\t\tAttn Matrix Dropout: 0\n",
      "\t\tQKV Dropout: 0\n",
      "\t\tL2 Coeff: 1e-06\n",
      "\t\tWarmup Steps: 0\n",
      "\t\tNormalization Scheme: batch\n",
      "\t\tAttention Time Windows: 1\n",
      "\t\tShifted Time Windows: False\n",
      "\t\tPosition Emb Type: abs\n",
      "\t\tRecon Loss Imp: 0\n",
      " ***                                  *** \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124f6213a27f4505b3be2b7c0ffce9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d3b8bd59274b08941fd7b242833683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf05a1fa89c64c9dbe281baad1d30e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c44d55f3c241b09ac3a221af0f00c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2982cf2fcc41b4af2b6726d60e85e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237664e313394c80b916cffc992aed9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1188629/3249414189.py\", line 47, in train\n",
      "    trainer.fit(forecaster, datamodule=data_module)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 771, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 724, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 812, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1237, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1324, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1354, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 269, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 171, in advance\n",
      "    batch = next(data_fetcher)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
      "    return self.fetching_function()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py\", line 259, in fetching_function\n",
      "    self._fetch_next_batch(self.dataloader_iter)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py\", line 273, in _fetch_next_batch\n",
      "    batch = next(iterator)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py\", line 553, in __next__\n",
      "    return self.request_next_batch(self.loader_iters)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py\", line 565, in request_next_batch\n",
      "    return apply_to_collection(loader_iters, Iterator, next)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\n",
      "    return function(data, *args, **kwargs)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1207, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1173, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1011, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/multiprocessing/queues.py\", line 107, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/dan/miniconda3/envs/spacetimeformer/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "Exception\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁████</td></tr><tr><td>train/acc</td><td>█▄▅▁</td></tr><tr><td>train/class_loss</td><td>██▂▁</td></tr><tr><td>train/forecast_loss</td><td>█▇▁▁</td></tr><tr><td>train/loss</td><td>█▇▁▁</td></tr><tr><td>train/mae</td><td>██▁▂</td></tr><tr><td>train/mape</td><td>▇▁▅█</td></tr><tr><td>train/mse</td><td>█▇▁▁</td></tr><tr><td>train/norm_mae</td><td>██▁▂</td></tr><tr><td>train/norm_mse</td><td>█▇▁▁</td></tr><tr><td>train/recon_loss</td><td>▁▁▁▁</td></tr><tr><td>train/smape</td><td>▁▃▅█</td></tr><tr><td>trainer/global_step</td><td>▁▁▃▃▆▆██</td></tr><tr><td>val/acc</td><td>▁▁▁▁</td></tr><tr><td>val/class_loss</td><td>█▅▃▁</td></tr><tr><td>val/forecast_loss</td><td>█▄▂▁</td></tr><tr><td>val/loss</td><td>█▄▂▁</td></tr><tr><td>val/mae</td><td>█▄▂▁</td></tr><tr><td>val/mape</td><td>█▅▃▁</td></tr><tr><td>val/mse</td><td>█▄▂▁</td></tr><tr><td>val/norm_mae</td><td>█▄▂▁</td></tr><tr><td>val/norm_mse</td><td>█▄▂▁</td></tr><tr><td>val/recon_loss</td><td>▁▁▁▁</td></tr><tr><td>val/smape</td><td>▂▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train/acc</td><td>0.33223</td></tr><tr><td>train/class_loss</td><td>1.19595</td></tr><tr><td>train/forecast_loss</td><td>1.14687</td></tr><tr><td>train/loss</td><td>1.26646</td></tr><tr><td>train/mae</td><td>0.64873</td></tr><tr><td>train/mape</td><td>10882.23684</td></tr><tr><td>train/mse</td><td>0.55224</td></tr><tr><td>train/norm_mae</td><td>0.93514</td></tr><tr><td>train/norm_mse</td><td>1.14686</td></tr><tr><td>train/recon_loss</td><td>-1.0</td></tr><tr><td>train/smape</td><td>1.5686</td></tr><tr><td>trainer/global_step</td><td>3</td></tr><tr><td>val/acc</td><td>0.33333</td></tr><tr><td>val/class_loss</td><td>1.16908</td></tr><tr><td>val/forecast_loss</td><td>1.11188</td></tr><tr><td>val/loss</td><td>1.22879</td></tr><tr><td>val/mae</td><td>0.63514</td></tr><tr><td>val/mape</td><td>10609.20009</td></tr><tr><td>val/mse</td><td>0.53725</td></tr><tr><td>val/norm_mae</td><td>0.91481</td></tr><tr><td>val/norm_mse</td><td>1.11187</td></tr><tr><td>val/recon_loss</td><td>-1.0</td></tr><tr><td>val/smape</td><td>1.40562</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-2</strong> at: <a href='https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/isqypcg7' target=\"_blank\">https://wandb.ai/ponderingparameters/smallnet_gpu_sweep/runs/isqypcg7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231129_130304-isqypcg7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'parameters': {\n",
    "        # random search\n",
    "        # 'batch_size':{'distribution': 'int_uniform', 'min': 0, 'max': 2000},\n",
    "        # 'workers':   {'distribution': 'int_uniform', 'min': 1, 'max': 20},\n",
    "        'base_lr':{'distribution': 'uniform', 'min': 1e-10, 'max': 0.1},\n",
    "        # grid search\n",
    "        # 'batch_size':{'values': [1, 512, 1024, 1536, 2000]},\n",
    "        # 'workers':   {'values': list(range(1,26,3))},\n",
    "        # 'no_val':{\"values\": [True,False]},\n",
    "        # 'no_time':{\"values\": [True,False]},\n",
    "        # 'no_space':{\"values\": [True,False]},\n",
    "        # 'no_given':{\"values\": [True,False]},\n",
    "        # 'gpus':{\"values\": [None,0]},\n",
    "        # 'strategy':{\"values\": ['dp',None]},\n",
    "\n",
    "        # fixed but maybe change...\n",
    "        'batch_size':{\"value\": 2000},\n",
    "        'workers':{\"value\": 10},\n",
    "        'init_lr':{\"value\": 1e-10},\n",
    "        'base_lr':{\"value\": 0.0005},\n",
    "\n",
    "        'context_points':{\"value\": 32},\n",
    "        'target_points':{\"value\": 2},\n",
    "        'd_model':{\"value\": 100},\n",
    "        'd_qk':{\"value\": 100},\n",
    "        'd_v':{\"value\": 100},\n",
    "        'd_ff':{\"value\": 400},\n",
    "        'n_heads':{\"value\": 1},\n",
    "        'enc_layers':{\"value\": 1},\n",
    "        'dec_layers':{\"value\": 1},\n",
    "        'global_self_attn':{\"value\": 'full'},\n",
    "        'local_self_attn':{\"value\": 'full'},\n",
    "        'global_cross_attn':{\"value\": 'full'},\n",
    "        'local_cross_attn':{\"value\": 'full'},\n",
    "        'no_val':{\"value\": False},\n",
    "        'no_time':{\"value\": True},\n",
    "        'no_space':{\"value\": True},\n",
    "        'no_given':{\"value\": True},\n",
    "\n",
    "        # directly set parameters\n",
    "        \"time_resolution\": {\"value\": 1},\n",
    "        \"start_token_len\": {\"value\": 0},\n",
    "        \"attn_factor\": {\"value\": 5},\n",
    "        \"dropout_emb\": {\"value\": 0.2},\n",
    "        \"dropout_attn_out\": {\"value\": 0},\n",
    "        \"dropout_attn_matrix\": {\"value\": 0},\n",
    "        \"dropout_qkv\": {\"value\": 0},\n",
    "        \"dropout_ff\": {\"value\": 0.3},\n",
    "        \"pos_emb_type\": {\"value\": 'abs'},\n",
    "        \"no_final_norm\": {\"value\": False},\n",
    "        \"performer_kernel\": {\"value\": 'relu'},\n",
    "        \"performer_redraw_interval\": {\"value\": 100},\n",
    "        \"attn_time_windows\": {\"value\": 1},\n",
    "        \"use_shifted_time_windows\": {\"value\": False},\n",
    "        \"norm\": {\"value\": 'batch'},\n",
    "        \"activation\": {\"value\": 'gelu'},\n",
    "        \"warmup_steps\": {\"value\": 0},\n",
    "        \"decay_factor\": {\"value\": 0.25},\n",
    "        \"initial_downsample_convs\": {\"value\": 0},\n",
    "        \"intermediate_downsample_convs\": {\"value\": 0},\n",
    "        \"embed_method\": {\"value\": 'spatio-temporal'},\n",
    "        \"l2_coeff\": {\"value\": 0.000001},\n",
    "        \"loss\": {\"value\": 'mse'},\n",
    "        \"class_loss_imp\": {\"value\": 0.1},\n",
    "        \"recon_loss_imp\": {\"value\": 0},\n",
    "        \"time_emb_dim\": {\"value\": 6},\n",
    "        \"null_value\": {\"value\": None},\n",
    "        \"pad_value\": {\"value\": None},\n",
    "        \"linear_window\": {\"value\": 0},\n",
    "        \"use_revin\": {\"value\": False},\n",
    "        \"linear_shared_weights\": {\"value\": False},\n",
    "        \"use_seasonal_decomp\": {\"value\": False},\n",
    "        \"recon_mask_skip_all\": {\"value\": 1},\n",
    "        \"recon_mask_max_seq_len\": {\"value\": 5},\n",
    "        \"recon_mask_drop_seq\": {\"value\": 0.2},\n",
    "        \"recon_mask_drop_standard\": {\"value\": 0.1},\n",
    "        \"recon_mask_drop_full\": {\"value\": 0.05},\n",
    "        \"null_value\": {\"value\": None},\n",
    "        \"pad_value\": {\"value\": None},\n",
    "    },\n",
    "    # only for bayes sweeps\n",
    "    'metric': {\n",
    "        'goal': 'minimize',\n",
    "        'name': 'val/smape'\n",
    "    },\n",
    "}\n",
    "\n",
    "# sweep_id=wandb.sweep(sweep_config, project=\"attn_additives_sweep\")\n",
    "sweep_id=wandb.sweep(sweep_config, project=\"smallnet_gpu_sweep\")\n",
    "# wandb.agent(sweep_id=sweep_id, function=train_model, count=5)\n",
    "wandb.agent(sweep_id=sweep_id, function=train, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
